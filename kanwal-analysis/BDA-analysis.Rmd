---
title: "Kanwal (2017) BDA Notebook"
author: "Ben"
date: "3/30/2018"
output: html_document
---

[Kanwal (2017)](https://www.ncbi.nlm.nih.gov/pubmed/28494263) present a test of Zipf's `Law of Abbreviation` -- that a universal design feature of human language emerges as a result of individuals optimising form-meaning mappings under competing pressures to communicate accurately (`expressivity`), but also efficiently (roughly, `learnabilty`). Their study uses miniature artificial language learning paradigm. They show that language users optimise form-mean mapping only when pressures for accuracy and effficency *both* operate during the communicative task.

In this analysis we explore the degree to which the observed behavior can be explained by more general purpose social reasoning mechanisms using a computational pragmatics model. We show that our model accounts for a large portion of the variance ($r^2=0.97$) across multiple conditions (both optimal and sub-optimal behavior).

While one interpretation of this finding frames the results as entirely pragmatics-driven. Instead we argue that the Zipfian result is a bi-product of pragmatic mechanims. 

Summary of paper:

Four conditions:

  * `combination`: both communicative (expressivity) and production cost (efficiency) pressures.
  
  * `accuracy`: only communicative pressure (no production cost).
  
  * `timing`: no communicative pressures (only production costs).
  
  * `neither`: not communicative pressures or productino cost. Note this scenario is not very interesting to us as it does not resemble any aspects of communication.
  
  ![Kanwal (2017), fig3](img/kanwal-2017-fig3.png)


```{r packages, message=FALSE, warning=FALSE, echo=FALSE}
library(dplyr)
library(ggplot2)
library(ggthemes)
library(rwebppl)
library(tidyr)
```

```{r echo=FALSE}
# getModelFile()
# ==============
# Return a model string from a .wppl file
#
# Parameters
# ----------
# modelFile: str
#  File path str
# 
# Returns
# -------
# str
#    Model str.
#
getModelFile <- function(modelFile) {
  readChar(modelFile, file.info(modelFile)$size)
}
```

# BDA - Modeling Zipf's Law of Abbreviation via Kanwal (2017)

Here we model participant behavior as pragmatic reasoning instantiated in the Rational speech-act family of models. We infer four hyperparmeters which encode different participant strategies (optimal in different conditions).

### BDA generative model

* `semantics`: $Unif(["natural", "none"])$ where
    * $natural: [[zop]] \in \{zopekil, zopudon\}, [[zopudon]] \in \{zopudon\}, [[zop]] \in \{zopekil\} \in \{zopekil\}$
    * $none: [[x]] \in \{zopekil, zopudon\}$
    
* `costs`: $Unif(["present", "not-present", "reversed"])$ where
    * $present: "zop":0.3, "zopudon":0.7, "zopekil":0.7$
    * $present: cost(zop) = cost(zopekil) = cost(zopudon) = 0$
    * $reversed: "zop":0.7, "zopudon":0.3, "zopekil":0.3$
    
* `recursion-level`: $Categorical([1, 2])$

* `needProbabilities`: $Categorical([present, not present, reversed])$
    * `present`: "zopudon":24,"zopekil":8,  
    * `not-present`: "zopudon":1,"zopekil":1,
    * `reversed`: "zopudon":8,"zopekil":24,

### Strategy mapping to hyperparams

Three conditions of interest:

  * `combination`:  `semantics`='natural', `costs`='present', `needProbabilities`='present'
  
  * `accuracy`:  `semantics`='natural', `costs`='not-present'
  
  * `timing`:  `semantics`='not-present', `costs`='present'
  
## Analysis

Note: this analysis includes 85% of participants as I'm having trouble modeling what appears to be fairly random behaviors... See `analysis.ipynb` for more information.
```{r getModelableData}
# Hueristic modelable data
f_modelable_data <- "../modelable-data-20180330.csv"
dfModelable <- read.csv(f_modelable_data)

# All data
f_all_data <- "../kanwal-preprocessed.csv"
dfAll <- read.csv(f_all_data) %>%
  mutate(frequent=round(frequent, 2),
         infrequent=round(infrequent, 2))
```

```{r setup-bda-model}
f_bda_model <- "../kanwal-BDA-20180330.wppl"
model_bda <- getModelFile(f_bda_model)
bda_data <- head(dfModelable)
nrow(dfModelable)

problemIPs <- c('70.198.5.150', 
                '117.217.210.9', 
                '65.183.140.246', 
                '24.253.233.194', 
                '24.20.229.200', 
                '108.196.136.202',
                '122.161.26.31')
# 24.74.13.244 only after 10000 attempts
# 50.153.162.232
# 
# but worked on second time
dfAll2 <- dfAll %>% filter(!(IP %in% problemIPs))
```

Note: slow running.
```{r run-bda-model}
# pt <- proc.time()
# df_bda <- rwebppl::webppl(model_bda, data=dfAll2, data_var='rData')
# et <- proc.time() - pt
# write.csv(df_bda, "bda-tuned-params-20180303.csv")
```

```{r optional-read-cached-data}
# If we haven't re-run the BDA predictives then load cached version.
if (!exists('df_bda')) {
  df_bda <- read.csv("bda-tuned-params-20180303.csv")
}
```

## BDA predictive
```{r generative-model}
fPath <- "../kanwal-generative-model-20180328.wppl"
m <- getModelFile(fPath)
```

Get posterior predictives...
```{r run-webppl}
dfSynthetic <- rwebppl::webppl(m, data=df_bda, data_var='rData')
```

## Empirical Kanwal (2017) data
```{r get-empirical-data}
fEmpiricalPath <- "../kanwal-preprocessed.csv" 
dfEmpirical <- read.csv(fEmpiricalPath)
```

```{r prepocessing-synthetic-data-names}
# Minor preprocessing
dfSynthetic <- dfSynthetic %>%
  rename(display_type=trialType) %>%
  mutate(label_type=ifelse(utterance=='zop', 'short', 'long'))
```

## Preprocessing
```{r prepocessing-synthetic-data-counts}
dfSyntheticCnts <-  dfSynthetic %>%
  group_by(IP, condition, display_type, label_type) %>%
  summarise(cnt=n())
```

Fill missing vals synthetic data (note I've alread carried this out in `analysis.ipynb` for empirical data)
```{r prepocessing-synthetic-data-fill-missing-vals}
display_types <- c('frequent', 'infrequent')
label_types <- c('short', 'long')

# New data frame for merging missing counts
dfPlaceholder <- data.frame(expand.grid(IP=unique(dfSynthetic$IP),
                                        condition=unique(dfSynthetic$condition),
                                        display_type=display_types,
                                        label_type=label_types)) %>%
  mutate(
    IP=as.character(IP),
    condition=as.character(condition),
    display_type=as.character(display_type),
    label_type=as.character(label_type),
    cnt=as.integer(0))

# First combine and take counts
dfJoin1 <- full_join(dfSyntheticCnts, dfPlaceholder, by=c('IP', 'condition', 'display_type', 'label_type', 'cnt')) %>%
  arrange(IP, condition, display_type) %>%
  group_by(IP, condition, display_type, label_type) %>%
  summarise(cnt=sum(cnt))

# We want to filter based on whether the group (IP, condition) ash *any* counts, so get these IDs
dfJoin2 <- full_join(dfSyntheticCnts, dfPlaceholder, by=c('IP', 'condition', 'display_type', 'label_type', 'cnt')) %>%
  arrange(IP, condition, display_type) %>%
  group_by(IP, condition, display_type, label_type) %>%
  summarise(cnt=sum(cnt)) %>%
  group_by(IP, condition) %>%
  summarise(groupTotal=sum(cnt))

dfSyntheticFinal <- full_join(dfJoin1, dfJoin2, by=c('IP', 'condition')) %>%
  filter(groupTotal == 32) %>%
  mutate(condition_total=ifelse(display_type=='frequent', 24, 8)) %>%
  group_by(IP, condition, display_type) %>%
  mutate(prop=cnt/condition_total) %>%
  select(IP, condition, display_type, label_type, prop) %>%
  filter(label_type=='short')
  # spread(display_type, prop)
```

Join empirical data and synthetic data
```{r preprocessing-join-empirical-synthetic-data}
dfSyntheticFinal <- dfSyntheticFinal %>%
  select(IP, condition, display_type, prop)

dfEmpiricalProcessed <- dfEmpirical %>%
  mutate(IP=as.character(IP),
         condition=as.character(condition)) %>%
  gather(display_type, prop, c(frequent, infrequent)) %>%
  select(IP, condition, display_type, prop)

dfEmpSynth <- left_join(dfSyntheticFinal, dfEmpiricalProcessed, by=c("IP", "condition", "display_type")) %>%
  gather(data_type, prop, c(prop.y, prop.x)) %>%
  select(IP, condition, display_type, data_type, prop) %>%
  mutate(data_type=ifelse(data_type=='prop.x', 'synthetic', 'empirical'))
```

### Evaluation

How do model predictions look compared to empirical data?
```{r plot-synthetic-vs-empirical}
dfEmpSynth %>%
  spread(display_type, prop) %>%
  ggplot(aes(x=frequent, y=infrequent, col=condition, group=IP)) +
    geom_point(aes(shape=data_type), alpha=0.5, size=2.5) +
    geom_line(alpha=0.7, col='grey', lty=2) +
    theme_few() +
    facet_grid(~condition)
```

Correlation
```{r correlation-synthetic-vs-empirical}
dfEmpSynthCor <- dfEmpSynth  %>%
  spread(data_type, prop)

paste("R^2:", round(cor(dfEmpSynthCor$empirical, dfEmpSynthCor$synthetic)^2, 3))
```

```{r plot-correlation}
dfEmpSynth %>%
  spread(data_type, prop) %>%
  ggplot(aes(x=synthetic, y=empirical)) +
    geom_jitter(aes(col=condition), alpha=0.5, width=0.01, height=0.01, size=2) +
    geom_smooth(method='lm') +
    ggtitle("Model vs Empirical predictions Kanwal (2017)") +
    theme_few() +
    theme(plot.title = element_text(hjust = 0.5))
```

### Restricting analysis to rational scenarios...
```{r correlation-synthetic-vs-empirical-conditions}
dfEmpSynthCor <- dfEmpSynth  %>%
  filter(condition != 'neither') %>%
  spread(data_type, prop)

paste("R^2:", round(cor(dfEmpSynthCor$empirical, dfEmpSynthCor$synthetic)^2, 3))
```

```{r plot-correlation-conditions}
dfEmpSynth %>%
  filter(condition != 'neither') %>%
  spread(data_type, prop) %>%
  ggplot(aes(x=synthetic, y=empirical)) +
    geom_jitter(aes(col=condition), alpha=0.5, width=0.01, height=0.01, size=2) +
    geom_smooth(method='lm') +
    ggtitle("Model vs Empirical predictions Kanwal (2017)") +
    theme_few() +
    theme(plot.title = element_text(hjust = 0.5))
```


### Baseline comparison  - naive model

The naive model employs the optimal strategy for communication in each of the three conditions.
* `combined`: always use `short` form for frequent object, always use `long` form for infrequent object
* `accuracy`: always use `long` form
* `time`: always use `short` form
```{r}
dfEmpSynthAdd <- dfEmpSynth %>%
  filter(data_type=='empirical') %>%
  mutate(baseline=ifelse((condition=='combined' & display_type=='frequent') | 
                               (condition=='accuracy' & display_type=='infrequent') |
                               (condition=='time'), 1.0, 0.0)) %>%
  select(IP, condition, display_type, baseline) %>%
  rename(prop=baseline) %>%
  mutate(data_type='baseline')

dfEmpSynthBaseline <- rbind(dfEmpSynth, dfEmpSynthAdd)
```

```{r plot-model-comparison-data}
dfEmpSynthBaseline %>%
  filter(condition != 'neither') %>%
  spread(display_type, prop) %>%
  ggplot() +
    geom_jitter(aes(x=frequent, y=infrequent, col=condition), alpha=0.5, width=0.01, height=0.01, size=2) +
    ggtitle("Model vs Empirical predictions Kanwal (2017)") +
    theme_few() +
    theme(plot.title = element_text(hjust = 0.5)) +
    facet_grid(~data_type)
```

```{r plot-model-comparison-corr}
dfEmpSynthBaseline %>%
  filter(condition != 'neither') %>%
  spread(data_type, prop) %>%
  gather(model, prop, c(baseline, synthetic)) %>%
  ggplot(aes(x=prop, y=empirical)) +
    geom_point(alpha=0.5, size=2) +
    geom_smooth(method='lm') +
    ggtitle("Model vs Empirical predictions Kanwal (2017)") +
    theme_few() +
    theme(plot.title = element_text(hjust = 0.5)) +
    facet_grid(~model)
```

```{r correlation-baseline}
dfBaselineCor <- dfEmpSynthBaseline %>%
  filter(condition != 'neither') %>%
  spread(data_type, prop)

cor(dfBaselineCor$baseline,
    dfBaselineCor$empirical)^2

```


